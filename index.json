[{"content":"","date":"5 April 2023","permalink":"/blog/","section":"Blog","summary":"","title":"Blog"},{"content":"","date":"5 April 2023","permalink":"/","section":"Casper Andersson","summary":"","title":"Casper Andersson"},{"content":"","date":"5 April 2023","permalink":"/tags/networks/","section":"Tags","summary":"","title":"networks"},{"content":" Computers in networks traditionally don\u0026rsquo;t have any knowledge of when other computers can/will transmit data. Dozens of devices transmitting data whenever they want will inevitably lead to collisions and congestions at one point or another, which in turn leads to packets not arriving as soon as they should. Packets arriving later than intended may affect what the receiver should do with it. Data can expire. If the timeframe for its usefulness has passed then the receiver must know this, or else it may perform actions based on old information. There exist techniques to improve predictability in networks, but this post will focus on a common understanding of time.\nClock synchronization across the internet typically uses software timestamping to make sure your computer clock shows the same as the rest of the world (disregarding timezones). In a best-case scenario software timestamping can reach a precision of under a millisecond, but also a worst-case of hundreds of milliseconds. To the human eye looking at a clock, this appears good enough, but machines may require much higher precision in certain use cases.\nA new level of precision # The IEEE 1588 standard defines the Precision Time Protocol, also known as PTP. This protocol allows synchronization of hardware clocks down to nanosecond precision in a local network. Devices achieve this by timestamping packets they send and receive and comparing the time, and estimating and adjusting according to the cable delay. But using software timestamping still limits the precision due to processor scheduling and other network traffic that creates variation in the actual transmission time.\nTo solve this there exist ethernet ports with support for hardware timestamping. PTP requires a device to know both the transmission and reception time. Sending over only the current time from the master clock would make the slave show an earlier time than the master since the master will have moved forward by the time the slave has received and adjusted the clock. The participating devices also need to determine how long delay the wire itself incurs. A long cable, or even a time-unaware switch, can add noticeable delays (noticeable from a nanosecond perspective).\nGood! Now we have established the requirement! But how does this help us?\nThe synchronization process of a slave clock consists of two steps:\nGetting the current time from a master clock Finding the cable delay and adding that to the time received from the master Step (1) involves the master sending the current time, taken as close to the wire as possible, in a Sync packet to the slave. PTP defines two methods for doing this: one-step and two-step. This is explained in more detail later. The slave can now update its clock to the provided timestamp. Upon reception, the packet gets timestamped again. Now the slave has receive_time - transmit_time = offset_from_master. The slave can now adjust its clock to the calculated offset. Though it has not yet compensated for the cable delay. If PTP only ever did step (1) the slave would always stay behind the master by cable_delay time. Devices would then end up further behind the further they are from the master, and each intermediate switch would add more to that.\nFor step (2) the slave sends a Delay_Req (delay request) to the master and records the transmission time (t1) for itself to use later. The master timestamps the reception time (t2) of the message and sends that back in a Delay_Resp (delay response) to the slave.\nBecause t1 was already cable_delay time behind the master clock, due to the cable delay on the previous Sync packet, the difference between t1 and t2 will now be cable_delay * 2. This means the slave clock should add (t2-t1)/2 to its clock. Now the master and slave clocks have successfully synchronized. The process will then repeat at regular intervals to make sure everything stays synchronized.\nSoftware daemon # The hardware only needs to implement the timestamping functionality to support PTP. But managing these different types of packets, as well as deciding who should be master and who should be slave, requires software. Usually in the form of a daemon. Richard Cochran maintains the most popular implementation of PTP in the project linuxptp.\nOne-step vs two-step # When the hardware receives a packet it will save the timestamp in packet metadata that can then be fetched by the receiving application. Simple enough!\nThe transmission poses more of a challenge since metadata can\u0026rsquo;t be included on the wire. As mentioned earlier, there exist two methods for handling this. The simplest one involves sending a packet, taking the timestamp from when it was sent, and then sending a Follow_Up packet that includes the transmission time of the first packet. This is called two-step timestamping.\nThe other alternative, one-step timestamping, requires hardware that can detect and modify the right fields in the PTP packets as they go out on the wire. That way the packet contains the data.\nThe following illustration shows the slave clock synchronizing to the master clock using two-step timestamping. The cable has a delay of 1 time unit. Described from the point of the master clock\u0026rsquo;s time:\nMaster Slave ┌───────────┐ │ │ 50─┼──────┐ ├─20 │ │ │ 51─┼────┐ └───►├─21 │ │ │ 52─┤ └─────►├─22-\u0026gt;51 │ │ 53─┤ ┌─────┼─52 │ │ │ 54─┤◄────┘ ├─53 │ │ 55─┼─────┐ ├─54 │ │ │ 56─┤ └────►├─55-\u0026gt;56 │ │ 57─┤ ├─57 └───────────┘ Master sends Sync packet and timestamps it (50). Slave receives Sync and timestamps it (21). Master sends Follow_Up containing the transmission time of Sync. Slave receives Follow_Up and calculates the difference between Sync transmission and reception. 50-21=29. Slave updates its clock by adjusting it +29. 22+29=51. Slave sends a Delay_Req and timestamps it (52). Master receives Delay_Req and timestamps it (54). Master sends back the Delay_Req timestamp in a Delay_Resp packet. Slave receives Delay_Resp. It now has the timestamps 52 and 54, which represents the cable delay multiplied by 2. Half comes from the packet delay request. And the other half comes from the earlier Sync packet where the slave knowingly set its time to cable_delay behind the master since it didn\u0026rsquo;t know the delay. The slave adjusts its time by (54-52)/2=1 and moves it 1 unit forward. The clocks are now synced. Using one-step works the same, with the only difference that the master does not need to send a Follow_Up packet.\nTwo-step only requires the networking hardware to be capable of timestamping packets. The timestamping happens either in the MAC hardware or the PHY hardware. The PHY will provide better accuracy since it allows timestamping to be the last action before the packet goes on the wire. Performing timestamping in the MAC can give slightly higher variation in accuracy, but still good enough for many use cases.\nThe following illustration shows an example layout of how a MAC and PHY would be attached in switching hardware. The PHY attaches directly to the cable.\n┌───┐ │CPU│ └─┬─┘ │ ┌─┴─┐ ┌───┤MAC├───┐ │ └─┬─┘ │ │ │ │ ┌─┴─┐ ┌─┴─┐ ┌─┴─┐ │PHY│ │PHY│ │PHY│ └▲─▼┘ └▲─▼┘ └▲─▼┘ For one-step, the hardware also needs the functionality to modify the packet, and that includes understanding the PTP packet layout. Using one-step results in fewer packets to handle and slightly faster convergence (time for all clocks in the network to get accurately synced) since it never has to wait for a second packet. Though with the introduction of the standard 802.1AS, it has been shown that two-step can perform just as well, and the extra traffic on the network becomes insignificant at the network speeds of today.\nSo why doesn\u0026rsquo;t everyone use one-step? At the surface, it looks good, but looking deeper one-step has some drawbacks. When reaching speeds of 10Gbit and higher it will incur penalties for the time spent taking the timestamp and modifying the packet1. The network transmits fast enough that it takes longer to add the time than the actual transmission. This means that the hardware can\u0026rsquo;t work at full wire speed while timestamping just before transmitting. To get around this the hardware could try to predict the transmission time and prepare the packet ahead of time. But that too has its issues as preparing ahead of time adds latency to all outgoing packets on that port. A not-so desirable trait in time-sensitive networks.\nhttps://www.ieee802.org/1/files/public/docs2015/ASRev-pannell-To-1-step-or-not-0315-v1.pdf\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"5 April 2023","permalink":"/blog/ptp-and-timestamping-methods/","section":"Blog","summary":"Computers in networks traditionally don\u0026rsquo;t have any knowledge of when other computers can/will transmit data. Dozens of devices transmitting data whenever they want will inevitably lead to collisions and congestions at one point or another, which in turn leads to packets not arriving as soon as they should. Packets arriving later than intended may affect what the receiver should do with it.","title":"PTP and timestamping methods"},{"content":"","date":"5 April 2023","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"This is just a short note to myself and anyone who encounters the same issue. While writing a post recently I wanted a numbered list that started with a number other than 1. Frustratingly, Jekyll does not support this. Jekyll always start lists with 1. I found this very inconvenient and tried to find a way around it. One solution is inline HTML. But then you are restricted to writing lists in HTML, and everything inside the lists needs to be formatted with HTML as well, if you want italics or code blocks, etc.\nAs I found out, Jekyll supports adding custom classes, IDs, and properties to HTML objects. To start my list at a different number I could simply do.\n{:start=\u0026#34;5\u0026#34;} 1. First item 2. Second item 3. Third item And the result is:\nFirst item Second item Third item Note that the {:} requires a blank line before it when styling a whole block, but it can also be inlined to apply to elements within a text. Classes and IDs can be added with {:.myclass} and {:#myid}. For more details on this I refer you to the place where I found it: Jekyll Tip: Adding Styling To Html Output\nAccording to the CommonMark markdown specification the rendered list should start with whatever the first number may be (within some restrictions, such as it can\u0026rsquo;t be negative and maximum 9 digits). The following numbers are disregarded and will only count up from the initial list item. Refer to 5.3 Lists and examples #265, #267, and #268.\n","date":"26 March 2023","permalink":"/blog/jekyll-markdown-lists-that-dont-start-on-1./","section":"Blog","summary":"This is just a short note to myself and anyone who encounters the same issue. While writing a post recently I wanted a numbered list that started with a number other than 1. Frustratingly, Jekyll does not support this. Jekyll always start lists with 1. I found this very inconvenient and tried to find a way around it.","title":"Jekyll markdown lists that don't start on 1."},{"content":"","date":"26 March 2023","permalink":"/tags/misc/","section":"Tags","summary":"","title":"misc"},{"content":"In my daily work I sometimes want to copy and modify raw frames as hexdumps. I will usually copy a hexdump from Wireshark or Tcpdump. Some times I have, however, written frames from scratch. Not very complex ones; nevertheless, it is nice to have the possibility to.\nThere are plenty of tools out there for building and sending frames. Two good ones I use are Nemesis and EasyFrames. They provide many options for creating different types of frames. Though sometimes you just want full freedom and not have to think about how to do something with the tool. I did not find any complete project that did this. I spent a lot of time googling. I found an easy way to send raw hex frames in Python on StackOverflow that I used for a bit. Eventually I decided to make it into a proper application. I wanted it in C, with the reason being that I might want to use it in an embedded enviroment where Python is not available. I also considered if Bash or any other common shell commands could do this, but nothing that I came up with. Most did not support raw frames. Otherwise, it would have been really sweet to have it as a simple shell script.\nHexend provides an easy way to repeatedly send any frame you want. A specific type of frame is causing you issues? Don\u0026rsquo;t bother with pcap playbacks or recreating the scenario to trigger the problem. Copy the hexdump (don\u0026rsquo;t include any line numbers) and start sending the frames. You can specify an amount of frames and an interval for sending them.\nHexend is also scriptable; it supports piping the frame to stdin. However, I\u0026rsquo;m not entirely sure of any use-case for this yet. Normally you will probably place the hexdump in a file and pass the filename as an argument to Hexend.\nHere is an example of piping a minimal frame (dst MAC, src MAC, EtherType) to hexend that gets sent to eth0 1000 times with no interval.\necho ffffffffffffaaaaaaaaaaaa0000 | hexend eth0 -c 1000 -i 0 Edit:\nI found a way to do it with shell scripting, depending on xxd and socat. The performance isn\u0026rsquo;t great for sending many frames quickly. But it is able to use the same input methods. I added a script file to the repo as an alternative. But all it does right now is just this:\ncat $2 | xxd -r -p | socat -u STDIN interface:$1 ","date":"29 September 2022","permalink":"/blog/hexend-send-raw-hex-frames/","section":"Blog","summary":"In my daily work I sometimes want to copy and modify raw frames as hexdumps. I will usually copy a hexdump from Wireshark or Tcpdump. Some times I have, however, written frames from scratch. Not very complex ones; nevertheless, it is nice to have the possibility to.\nThere are plenty of tools out there for building and sending frames.","title":"Hexend - Send raw hex frames"},{"content":"","date":"29 September 2022","permalink":"/tags/linux/","section":"Tags","summary":"","title":"linux"},{"content":"","date":"29 September 2022","permalink":"/tags/programming/","section":"Tags","summary":"","title":"programming"},{"content":"This is a short story from $DAYJOB about my discovery and investigations of an issue with the build system.\nOne day when building our code I suddenly got a segmentation fault when building. An odd occurrence. I could not recall any changes to the build system and checking the Git log I could not find any changes that would affect it. It got even more mysterious as I went back in the Git history and would still have the crash. I managed to narrow the issue down to one package which was being built slightly differently than our other packages. Still, it didn\u0026rsquo;t make sense why it was failing.\nThe weirdest part of all this was that it was failing between two steps in the build process. I added debug prints to the build system and I could see that it finished the configuration step, but never reached the start of the build step. I did not dig deeper into the build system here, as it is very complex Makefile code. At this point, I knew there was some issue with Make. It output a core dump upon crashing, so my next step was to take a look at that core dump. Find out how it is crashing.\nThe core dump led me to a function called func_filter_filterout, which had a loop that looked like this (shortened):\nwhile ((p = find_next_token (\u0026amp;word_iterator, \u0026amp;len)) != 0) { struct a_word *word = alloca (sizeof (struct a_word)); *wordtail = word; wordtail = \u0026amp;word-\u0026gt;next; word-\u0026gt;str = p; The crash would occur on the last line, but the key here is the function call to alloca. It allocates memory similar to malloc, with the difference that the allocation happens on the stack. This allows the memory to later be freed automatically when the function exits. Reading the manpage alloca(3) we can find\nBUGS There is no error indication if the stack frame cannot be extended. (However, after a failed allocation, the program is likely to receive a SIGSEGV signal if it attempts to access the unallocated space.) This is exactly what was happening. When printing the word address in the code above I could see the address going up and down a lot (indicating it was allocating for a while, then freeing and the function being called again). When it reached the point where Make would crash I noticed the address increasing continuously for a while and eventually crashing.\nCurious as to why it was stuck in a seemingly infinite loop, or as it turns out, just a very long one I changed my print to output p, the strings being iterated over. The output showed Make variables for many packages, and many we did not use. The packages were available for selection in the build system but were not selected and it did not make sense why Make would iterate over them when building a completely unrelated package. It did not do this iteration at all when building other packages.\nFor some reason, Make would start iterating over all variables. I did not delve further into this right now. I switched focus. Why did it start happening now? Why was it never an issue before?\nIt didn\u0026rsquo;t take too long for me to realize that a couple of weeks prior I had upgraded Ubuntu on my work laptop from 21.04 to 22.04. Could they have upgraded the Make version? Nope, Make 4.3 was released about 3 years ago and has not had a new release. I talked to a colleague who was still on Ubuntu 21.04 and we both had the Make 4.3. He sent me his Make binary for me to test. Surprisingly, it works fine. Make 4.2.1 from Ubuntu 18.04 also works fine. It is not the environment that is the issue. Something with the Make version shipped with Ubuntu 22.04 is different. Well, maybe Ubuntu has some internal patches to Make that introduced the bug? Let\u0026rsquo;s try building Make 4.3 from source!\nCRASH! The issue exists on the original release too?! Had Ubuntu fixed this previously and now removed the fix? Are there differences in how it\u0026rsquo;s built? Even more questions I have yet to find an answer to.\nTesting it with upstream Make did not cause the crash, but a lot has been refactored since the last release of Make.\nAt this point, I turned away from chasing Make. At least using upstream works fine. Being forced to build with tools from older Ubuntu versions would be awful in the long run. It could end up with the build system using a Docker container with Ubuntu 21.04 to build it for many years in the future.\nI turned my attention back to the \u0026ldquo;faulty\u0026rdquo; package in our build system. Since it was never really handled in an ideal way I decided to dig into that instead, resulting in the package being split up and treated the same as every package should be treated in the build system.\nOnly after doing this did I discover this piece of Make code: $(.VARIABLES). I realize I should have looked closer at this code earlier, but at a glance the code around it didn\u0026rsquo;t do anything groundbreaking. It turns out this is a special variable in Make that holds all other variables\u0026rsquo; names, and it was being iterated over.\nI still have not found out why it suddenly became an issue on Ubuntu 22, but at least I found what caused the issue. This journey has been a very interesting and educational one. I learnt a lot about our build system and Make in general. Time well spent!\n","date":"17 September 2022","permalink":"/blog/the-day-make-started-crashing/","section":"Blog","summary":"This is a short story from $DAYJOB about my discovery and investigations of an issue with the build system.\nOne day when building our code I suddenly got a segmentation fault when building. An odd occurrence. I could not recall any changes to the build system and checking the Git log I could not find any changes that would affect it.","title":"The day Make started crashing"},{"content":"A couple months ago a colleague showed me his post on a life without sudo. In it he demonstrates the elegant use of Linux capabilities(7). If you aren\u0026rsquo;t familiar with capabilities I recommend reading his post first. I started using it myself and found it incredibly convenient. I would run sudo many times per day before. This would usually be to do some network-related activity such as sending raw packets or changing network interfaces. These I know require the capabilities CAP_NET_RAW and CAP_NET_ADMIN. But once in a while I come across something where I do not know which capability it uses. Network namespaces was such a thing. Turns out it requires CAP_SYS_ADMIN and CAP_DAC_OVERRIDE.\nTo make my new life without sudo even simpler I wrote capmon - a Linux capabilities monitor. It allows you to monitor the capability checks that Linux does, and is able to filter and aggregate them for you.\nHow it works # It makes use of kprobe-based event tracing. The kernel config CONFIG_KPROBE_EVENTS exposes a debugfs (debug file system) that you can interact with by reading and writing to files. It lets you set debug probes (kprobes) on kernel functions and print out information when they are called or returns. In the case of capmon it listens to calls to functions that do capability checks and prints the argument int cap which holds an integer representing the capability it is checking. It also prints the name of the process calling it and its process id (pid). This all ends up in a log file at /sys/kernel/debug/tracing/trace_pipe that capmon actively reads from when data comes in. The data is parsed and presented in a more user-friendly manner.\nIt features three filter options: filter by process name, pid, or capability being checked. Process name supports regular expressions. The filters can be combined freely. Filters of the same type are treated as OR, while filters of different types are treated as AND. Filtering is great, but one feature which I think really helps is the summary mode. Sometimes there can be a lot of output. The summary mode allows you to gather all checks by either process name or pid. At the end it will print out which names/id\u0026rsquo;s checked which capabilities.\nHow to use it # capmon itself uses CAP_DAC_OVERRIDE, in case you don\u0026rsquo;t want to use sudo for it. If you want to find the capabilities of a program you start by running capmon. Possibly with some filters or flags. Now we will use summary mode to find the required permission. For example:\ncapmon -s name Then you run the program without sudo. Now you can either add the capability you saw pop up in capmon, or stop capmon using \u0026lt;Ctrl-C\u0026gt; to see the summary mode. It may fail on the first capability check and stop there. So you may have to add that capability then run it again to have it fail on the next one.\nIssues # As of release 1.1 of capmon there are some issues with the design that I would like to resolve in the future.\nWhat to monitor? # Right now it shows more capability checks than necessary, and sometimes it might still not show all you want. This is because capability checks take different paths through the kernel, though they all seem to converge to cap_capable. But cap_capable is called a lot and for things you might not care about. I added that as an extra flag -a. By default it monitors ns_capable and capable_wrt_inode_uidgid. A lot of checks might happen due to capabilities I think the user might have by default. For example, CAP_SYS_PTRACE is called a lot when you run htop. Even though I never explicitly gave that capability.\nInteracting with kprobe events # The debugfs interface works fine for manual debugging. But it feels too unstable to be used for an application. It uses a common output file and it could easily break through manually touching the debugfs. Or even if some other application wants to do a similar thing. They might send a clear-all command to the debufs.\nI would like to rewrite this using libbpf, to write proper code that attaches to the functions instead of sending raw strings to files.\n","date":"26 August 2022","permalink":"/blog/a-simpler-life-without-sudo/","section":"Blog","summary":"A couple months ago a colleague showed me his post on a life without sudo. In it he demonstrates the elegant use of Linux capabilities(7). If you aren\u0026rsquo;t familiar with capabilities I recommend reading his post first. I started using it myself and found it incredibly convenient. I would run sudo many times per day before.","title":"A simpler life without sudo"},{"content":"Let\u0026rsquo;s dive a little deeper into Time-Aware Shapers, specified in the IEEE 802.1Qbv standard. For a light introduction go read my intro to TSN.\nGates # The shapers are applied on egress and each shaper has a list of time slots, where each time slot specifies a duration, operation, and gate_mask. The duration represents how long the time slot is. The gate_mask specifies which egress queues are open during that time. Multiple queues can be open at the same time, at which point it treats it as regular Strict Priority between those queues, i.e., higher priority goes first. operation will be covered later. Time-Aware Shapers can have a theoretically infinite number of these time slots, also known as gates, but in practice there will of course be a limit to what both the software and hardware can support. The sum of the gates\u0026rsquo; durations defines the cycle time. When it has iterated through all the gates it restarts with the first gate again. Below is an example of a schedule with two gates, one which opens priorities 0-3 and one which opens priorities 4-7.\n|---------|---------|---------|---------| | 0,1,2,3 | 4,5,6,7 | 0,1,2,3 | 4,5,6,7 | ... |---------|---------|---------|---------| You should always make sure that all possible priorities in your system should be able to send at least during one gate. Otherwise it will take up space in the queue and never be sent. You can of course use only priorities 0-2 if you wish, but then you must make sure that no priority is ever mapped to the rest. The priority is usually the PCP or DSCP value, but how you map that to the internal priority of the switch is up to you. Since DSCP can have 64 different values you already need some sort of reduced mapping to the 8 queues used by the shaper.\nThe lower limit of what defines reasonable durations is that frames need to still be able to pass through with little interruption. Too short and it will start causing more problems that it solves. With too short gates it could result in frames either not fitting in the gate and start encroaching on the next time slot, or being preempted a lot if used with Frame Preemption.\nThe maximum latency for your requirements defines the upper limit of a single gate\u0026rsquo;s duration A low-priority gate cannot have a duration longer than the maximum latency, otherwise the higher priorities has to wait too long for their turn. The total cycle time has no theoretical upper limit, but at some point it will be more worth to have it cycle back to the start instead of defining more gates.\nAll gates have a guard band at the end of their duration. During the guard band no new frames can be sent, it only allows already started frames to finish. This is to avoid frames encroaching on the next time slot. To completely avoid it you can set the guard band to the maximum size of a frame, 1518 bytes. This means that if the frame started sending it will be guaranteed to finish before the gate closes. However, this could end up wasting a lot of time when a frame finishes very early into the guard band and it has to idle until the next gate.\n|------------------|-------------| | Gate 1 | GB | Gate 2 | GB | |------------------|-------------| Frame Preemption # Frame Preemption can be used in conjunction with Time-Aware Shapers to make them more efficient. Frame preemption was covered briefly in the TSN introduction post. A quick recap. It requires frames to be classified as express or non-express frames. It allows non-express frames to be interrupted by express frames to allow the express frame to send immediately.\nWhen used with Time-Aware Shaper you apply the different Frame Preemption options SetGateStates (S), Set-And-Hold-MAC (H), and Set-And-Release-MAC (R) to the different gates. S does nothing with respect to Frame Preemption, but is an indicator that the guard band needs to be longer before it starts. H makes sure any frames from previous gate are preempted when the gate starts. R allows non-express frames to send again. H allows the guard bands to be reduced drastically because now they can preempt a frame when reached. It only needs to add the extra CRC checksum and then it can move on to the next gate. Shorter guard bands enables better bandwidth usage.\nIf you have multiple express gates (H) in a row then it won\u0026rsquo;t be able to preempt in preparation for the next gate, but then you also have bad design :).\n","date":"25 August 2022","permalink":"/blog/tsn-time-aware-shaper/","section":"Blog","summary":"Let\u0026rsquo;s dive a little deeper into Time-Aware Shapers, specified in the IEEE 802.1Qbv standard. For a light introduction go read my intro to TSN.\nGates # The shapers are applied on egress and each shaper has a list of time slots, where each time slot specifies a duration, operation, and gate_mask.","title":"TSN: Time-Aware Shaper"},{"content":" Disclaimer! I am in no way an expert at this. I\u0026rsquo;m learning it as part of a research project at work. This will be the first post in what I hope to be a series of posts on TSN. What is it? # Time-Sensitive Networking (TSN) is a topic in the networking world where there exists data frames that absolutely must arrive within a limited time. It is a fairly new topic and some of the techniques are not completely industry-tested yet. It originates from the sound and video world where they have sound and video that must arrive very quickly. It was originally called Audio Video Bridging (AVB), but was renamed to Time-Sensitive Networking (TSN) in 2012.\nIt could be used at concerts, for example. The sound data must to travel from the microphones to all the speakers, and maybe some cameras to stream to the screen; and it all has to happen very quickly. Humans are very sensitive to delays in sound and video when it doesn\u0026rsquo;t match up with the reality. To make this even more complex there is often other types of data travelling the network as well. You could make the argument that the sound should use its own cables; however, that is extra maintenance and requires a separate network to run on. It is convenient to be able to use the same network for everything.\nTo work around this they have come up with several techniques for handling Quality of Service (QoS) in networks. I will cover some QoS techniques now, and future posts will go more in-depth on some of them. These are all defined in IEEE standards.\nTSN techniques # Strict Priority (802.1Q) # The most basic form of QoS. This, as well as several of the below techniques, are based on the concept of multiple egress queues. Usually 8 of them. With 8 queues you can do a 1-to-1 mapping from the Priority Code Point (PCP) in the VLAN tag. There are some techniques to set the priority from software (see man mqprio). In Linux, this is the skb-\u0026gt;priority field. But when you use QoS you usually want the frames to only pass through the hardware. There is currently only support in the Linux kernel to set this for this for the DSCP field (man dcb-app), but hopefully we can get a proper way to set this for PCP as well. It is already supported by a lot of the hardware. There are other ways to do this in the hardware as well, but not all are ideal.\nAs for the algorithm itself, it is very simple. It transmits frames in order of priority. When it starts transmitting a frames it picks from the highest priority queue that is not empty. A lower priority queue will only transmit if all higher priority queues are empty. Below is an illustration of 3 transmit queues with frames A-H, where frames in queue 2 would have the highest priority.\nQueue ---------------------- 0 -\u0026gt; [H] [G] [F] [D] -\u0026gt; ---------------------- 1 -\u0026gt; [E] [C] -\u0026gt; ---------------------- 2 -\u0026gt; [B] [A] -\u0026gt; ---------------------- Time-Aware Shaper (802.1Qbv) # This extends the Strict Priority algorithm by adding a time aspect to it and splitting the time into several slots where different priorities are allowed to send in each slot. For example, it could have 2 slots, one where only priority 7 (highest) is allowed to send, and another where priority 0-6 are allowed to send. The time slots can be of different length. For the second slot there are 7 different priorities that can send, so between those it applies Strict Priority.\nTime-Aware Shapers can run in software, but the benefit it gives is completely lost. To be at all useful it needs to be offloaded to hardware, which also requires a PTP hardware clock. On top of the clock itself it should also be time synced to all other switches in the network. Otherwise, there is also very little point in using it. If all switches are synced it will result in the same priorities all being open at once in the network; ideally letting the frames flow all the way to their destination without being interrupted by other traffic. To put it simply, it can reserve bandwidth for the different priorities and giving the network a deterministic behavior (at least for high priorities), but of course this assumes you aren\u0026rsquo;t overloading the network itself. If you try to overload the link it will obviously drop and delay frames.\n[Read more\u0026hellip;]({% post_url networks/2022-08-25-time-aware-shaper %})\nCredit-Based Shaper (802.1Qav) # The original TSN technique that was invented for the purpose of audio and video. It reduces the congestion in the network by evening out bursts. It is a form of fair queueing. Like Strict Priority, this also uses multiple egress queues. Each queue holds a credit score that goes up when a queue is not transmitting, and down when it transmits. When the credit score goes negative it is not allowed to transmit. By evening out the traffic to get rid of bursts the data can flow more freely in the network. This is especially useful when there are many devices in the network that may send bursts. If all send a burst at once it can result in the queues filling up where the bursts meet.\nFrame Preemption (802.1Qbu) # Frame preemption is the only of the priority-based TSN techniques that requires both ends of a link to support its protocol. The ones above can all operate on a single switch, though ideally used in a network were all are running the same technique. It also requires hardware support. With frame preemption both sides work together to provide faster delivery speed. To begin, we first have to define which priorities (queues) are to be considered preemptible. This is done independently on each switch.\nIf a preemptible frame is currently being transmitted and an express (non-preemptible) frame arrives to the queue it will almost immediately stop the preemptible frame (it preempts it). To not have wasted all the work already done sending the frame it appends a CRC32 checksum to the end of the partial frame, as well as inverts the last 16 bits of the CRC value to distinguish a partial frame from a regular frame. When that is done it can start sending the express frame. The partial frame is stored in a separate buffer on the other end and waits for the other half of its frame to arrive. The other half is sent when no more express traffic is available to send.\nFrame Replication and Elimination for Reliability (802.1CB) # The final technique for this post is the only one not dependent on multiple queues and priorities. Rather than providing fast delivery it is a form of redundancy. The idea is that it duplicates frames and sends them different paths in a ring or otherwise redundant topology. In the case of one switch failing it doesn\u0026rsquo;t even have to wait for the switches to learn the new path. The frames are already on their way the other path as well. To not get duplicate frames at the destination it eliminates any duplicates where they meet again, ideally as close to the destination as possible; possibly even at the end device. Same as frame preemption, this requires the mergeing device to also support the protocol. The intermediary switches do not need to support it, they just need to forward the frame.\nKeeping track of duplicates in the merging device is done with the help of a sequence number in the duplicated frames. This is called the R-tag and it has a 16-bits field to store the sequence number. The R-tag is then removed when a frame arrives at the merging device, and any following frames with the same sequence numbers are discarded.\nIn the case of multiple senders to the same merging device it can employ a stream identification function to identify which data stream a frame belongs to. Two frames can have the same sequence number but belong to different streams, and we don\u0026rsquo;t want one of those to be discarded because they are not the same frame.\nTSN today # TSN techniques are still considered fairly new and is not entirely industry-proven. It is starting to appear more and more in factories with the advent of Industry 4.0 and companies wanting to make their factories smart and more modern. By using a single network for everything you simplify connections and reduce the amount of cables. The time-sensitive aspect comes from, for example, control systems that need to send instructions instantly other machines. It has also gained traction in the automobile industry for use inside cars to connect various smart devices such as cameras, sensors, control devices, etc., with the main computers.\n","date":"7 June 2022","permalink":"/blog/what-is-time-sensitive-networking/","section":"Blog","summary":"Disclaimer! I am in no way an expert at this. I\u0026rsquo;m learning it as part of a research project at work. This will be the first post in what I hope to be a series of posts on TSN. What is it? # Time-Sensitive Networking (TSN) is a topic in the networking world where there exists data frames that absolutely must arrive within a limited time.","title":"What is Time-Sensitive Networking?"},{"content":"A network switch has multiple ports to send and receive data on. To manage this there is a component called \u0026ldquo;bridge\u0026rdquo; inside it. In Linux the bridge is defined as a network interface, but it it can also be offloaded to hardware (at least parts of it). The bridge is responsible for connecting different networks with each other. A packet coming in on one connection has the possibility to go out on any of the other bridged connections.\nForwarding Database (fdb) # The Forwarding Database (fdb) stores the information about which bridged connection a data packet should use depending on what the destination is. An fdb entry needs to store the MAC address of the known destination and which connection it should use to reach that. The connection is specified as an interface, e.g., eth3 or vlan3. When a packet arrives at the bridge the MAC address will be inspected and matched to the fdb. If an entry is found it will be forwarded to that interface. If none is found it is treated as unknown and will be flooded to all ports of the same bridge (with the exception for any ports that have flooding disabled).\nHopefully, the flood will result in the destination responding to the packet, sending a reply back to the source. When the reply passes through the bridge it sees which interface it arrived on and will save that in the fdb for next time. Now packets have passed through the bridge from both devices and it has learned which interface each destination is on. Next time they communicate the bridge will find the entries in the fdb and forward the packets correctly.\nShow the contents of the fdb in Linux\nbridge fdb show Ageing # To avoid the fdb filling up with old entries a bridge can use ageing. It keeps count of how many seconds has passed since each MAC address sent a packet through the bridge; the counter is reset when a packet from that MAC address enters the bridge. When the age reaches a set threshold it will be removed from the fdb. For example, if a device stops responding to requests it will never refresh the age and the fdb entry will eventually be forgotten since the device is no longer considered part of the network.\nWhat if you want to have a device that only listens to requests? Easy! You can get around the ageing by setting a static fdb entry. These entries will never age, they stay there until you say otherwise.\nAdd a MAC address to be forwarded to the specified interface. To make it static you simply add static at the end\nbridge fdb add \u0026lt;MAC\u0026gt; dev \u0026lt;INTERFACE\u0026gt; Multicast database (mdb) # The kernel also stores a database of all the multicast groups, which can be seen if you run\nbridge mdb show For multicast it will create a entry when it gets an IGMP Join message. It creates a entry for that group and marks the port that it arrived on. The goal of multicast is to be able to send one message to multiple recipients. Which means that the mdb must store all ports that are in the group, and then remove them when they leave. This is typically stored in a port masks. For a switch with 8 ports, where ports 2 and 4 are in the group, it could look like this 00001010 (represented by the second and fourth bit). This indicates the second and fourth port are in the group. When all ports eventually leave the group it can remove the entry.\nHardware offloading # Sometimes you want a bit higher performance. For those times you can use a specialized hardware circuit for network switching. You get less load on your CPU and higher throughput because the packets are switched directly in the hardware and never touches the CPU. One drawback of this is that the hardware only has the features it was built with. If you ever lack some feature you can\u0026rsquo;t simply write some code for it. But it usually comes with at least some common features, such as its own fdb and mdb that are stored in its own internal memory.\nThe fdb and mdb are stored in a table with fast lookup to quickly switch the packets. The table might look something like this (simplified, it will usually contain more information, e.g., age and if it is static or not)\n------------------------------------------------- | MAC | VLAN | TYPE | DESTINATION | |-----------------------------------------------| | 00:00:00:00:00:01 | 1 | UC | 2 | | 00:00:00:12:ad:fd | 2 | UC | 5 | | 01:00:5e:01:02:03 | 2 | MC | 1 | ------------------------------------------------- The type indicates Unicast or Multicast. The unicast entries points at the port it should send the packet to. Multicast, on the other hand, points to an index in another table. This is where the port mask is stored.\nEntries to this table can be added if the device driver supports it. Then an entry will be added to both software and hardware, since it goes through software first. All multicast addresses are added through software because that is where the IGMP protocol is handled. Though, some entries may exist in hardware only. This happens when the hardware learns unicast entries.\nThese are all things the bridge manages, whether it is a software defined bridge ,like the one in Linux, or if it has been offloaded to a hardware circuit. This has been a little summary of what I have learned at work recently. Thanks for reading!\n","date":"18 February 2022","permalink":"/blog/network-bridge-forwarding-and-learning/","section":"Blog","summary":"A network switch has multiple ports to send and receive data on. To manage this there is a component called \u0026ldquo;bridge\u0026rdquo; inside it. In Linux the bridge is defined as a network interface, but it it can also be offloaded to hardware (at least parts of it). The bridge is responsible for connecting different networks with each other.","title":"Network bridge forwarding and learning"},{"content":"In a previous post I talked about deterministic functions and some useful properties they have. I recommend you read that one first if you haven\u0026rsquo;t already. But deterministic functions aren\u0026rsquo;t all that useful to get tasks done. They only transform data from one form to another, but cannot actually read input from the console or even print to the console. A program consisting of only deterministic functions will always perform the same calculation, and given that it doesn\u0026rsquo;t have input or output it will only use whatever numbers it was compiled with. It essentially becomes a black box that does some computation without ever showing the result. It is just a waste of time. To do anything useful we need input and output (IO) in one way or another. This doesn\u0026rsquo;t mean every function should be nondeterministic. I still encourage you to make as much as possible deterministic, for the reasons outlined in the previous post. But IO is a must for any useful program.\nTypes of nondeterminism # Nondeterminism comes in many forms. There were 3 main ones that I could think of, that I will talk about here. Though you might be able to find more, and probably different subcategories of each of them as well.\nGlobal state means to change the values of variables that live in the global scope, or any scope that is outside the function. Static class variables are also included here. The way it creates nondeterminism is pretty obvious. Changing state will make the function behave differently the next time. Modifying a reference is another way to change the state. References are a pointer to a variable. If you pass a reference to a variable you can then modify the original. The function below demonstrates nondeterminism through a global variable.\nx = 10 def f(y): global x x += 1 return y + x print(f(5)) # prints 16 print(f(5)) # prints 17 IO is also the obvious one which I\u0026rsquo;ve already mentioned. Reading from or printing to console, reading/writing files, http requests, database requests. Anything that interacts with the world outside of the program itself. This is because everything outside the program is subject to possible changes at any time (from the program\u0026rsquo;s perspective). The data in the database may change. The file it reads may have changed. Random values is a subcategory of IO since random numbers need to be seeded from the operating system, unless you want the same random sequence every time you execute. Random values will therefore also contribute to nondeterminism.\nExceptions interrupt the flow of the program when they occur. Exceptions as a concept is a problem for determinism since the program no longer executes as expected. Zero-division exception is a common exception that can occur in many places and even in languages that don\u0026rsquo;t want to use exceptions, like Haskell. You could do controlled handling of zero division, but doing that everywhere is a massive pain. Though having an exception crash the entire program is a fair way of handling errors. Determinism becomes even harder when raising exceptions and specifically catching them is an integral part of the language. Now a function can either return normally, or it can return with an exception that may or may not be caught. If you do catch it then you have two types of returns you can do, one which can come from anywhere deep inside that function call. And sometimes you may not even be aware of certain exceptions that may happen in your code.\nInteresting takes on handling nondeterminism # Haskell is a language that tries to avoid nondeterminism as much as possible, and therefore has some interesting ways to handle the above mentioned problems. Global state is easily solved by simply not allowing any global state. You can write code perfectly fine without it. This was proven by Alonzo Church, the creator of Lambda calculus. Lambda calculus is functionally equivalent to the Turing machine that Alan Turing created, of which all modern computers are based on.\nIO is significantly tricker, and originally Haskell was just a black box that you compiled, ran, and then you would be able to look at the return value of the main function once it was done. It had no actual IO support. As time went on they added support for IO in the main function, but everything else had to be deterministic. Finally they added support for IO everywhere, though very restricted to be able to enforce determinism. IO in Haskell is wrapped in a monad (I will not explain what a monad is). This meant that any function that does IO must return an IO monad. Therefore, any function that does IO must eventually return its IO operation back to the main function. Because of Haskell\u0026rsquo;s type system the IO must also be included in the function types. Looking at a function signature you can immediately know if it does any IO or not. This makes you more wary of using IO. (On a side note, Haskell has debugging functions that lets you print values anywhere, but this is strictly for debugging and they live in the debugging module).\nYet again, Haskell is a prime example of how exceptions can be handled. It has the types Maybe and Either. Maybe simply returns Just a value, or Nothing. This would be similar to having a function return a value, or null. With one slight difference. In Haskell you have to handle the type by checking if it is Just or Nothing before being able to use the value inside it. It\u0026rsquo;s impossible to get something like NullPointerException later because you forgot to check for null. Either type is an extension to Maybe in that instead of Nothing it returns something else. This is usually an error message in the form of a string. But it could be any other value, though you still know whether it was the right or wrong return value.\nInterestingly enough, Java has also built upon this concept of making the exceptions explicit and forcing you to handle it. If a function can throw some exception it has to be declared in the type signature. Anywhere that function is called you must either handle that exception or explicitly write that your new function can also throw that exception since it will propagate up the call stack. And regarding the handling of null values Kotlin uses a method similar to Haskell by forcing you to check if it\u0026rsquo;s null or not before you can use the value.\nThe reason I wanted to talk about nondeterminism is because being aware of it is an important step to writing better code. As we concluded in the previous post, deterministic functions are easier to debug. I encourage you to make your functions deterministic whenever possible and keeping in mind the possible ways you might break that property.\n","date":"1 January 2022","permalink":"/blog/nondeterministic-functions/","section":"Blog","summary":"In a previous post I talked about deterministic functions and some useful properties they have. I recommend you read that one first if you haven\u0026rsquo;t already. But deterministic functions aren\u0026rsquo;t all that useful to get tasks done. They only transform data from one form to another, but cannot actually read input from the console or even print to the console.","title":"Nondeterministic functions"},{"content":"Recently I got the idea that I wanted to experiment with using X11 directly, instead of some higher-level library where buttons and fields already exist as objects. The goal was to get a better idea of how the graphics and window systems works in Linux (X11 specifically). This wasn\u0026rsquo;t a huge project and I only got to see parts of it before moving on, but it was a very interesting experience. Especially for someone like me who has barely done any kind of graphics programming before. In doing this project I started with a template from this guide that contained setting up a window and listening to user events inside the window. The official documentation was also very useful, along with the manpages in Linux. This post contains some short explanations of problems I encountered and discoveries I made during this project. Github: https://github.com/cappe987/graphics-simulation.\nGIF TEMPORARILY REMOVED DUE TO ISSUES WITH GO HUGO\nThe gif above shows my project. It is small blue balls bouncing on green balls. The blue balls fall from top to bottom and green balls can be placed or removed by left and right clicking. I know the bounce physics isn\u0026rsquo;t correct but ignore that for now. The goal was just to learn about X11, not to make great physics.\nHow X11 handles windows and input # X11 has 4 important variables.\nDisplay* display; int screen; Window window; GC gc; display is a pointer to the X Server and is passed to almost every function in X11. screen refers to which monitor to use. window is the actual window that you are working with. gc stands for Graphics Context and holds information on how things should be drawn. Information such as colors, fonts, etc. Any changes made to the window requires both the display and the window to be passed to the function. If it should draw something on the window itself then the gc also needs to be passed.\nX11 handles input through events. It waits for events to happen and then it runs. When nothing is happening it is not actively running any code. By default it doesn\u0026rsquo;t listen to any events. You need to set a mask for which events you want to listen to. This is done through a bitmask with the bitwise or-operator | in C.\nHere\u0026rsquo;s an example of setting the events\nXSelectInput(display, window, ExposureMask | ButtonPressMask) This code sets the window to only generate events for exposure (when contents in the window can no longer be seen due to resizing) and button press (mouse buttons). Button events is probably the simplest to understand, it generates an event when you click a button on the mouse, and the event struct received will contain information about which button. Exposure event is useful if you expect the user to resize the window. Because when it is resized it may need to be redrawn if some things in the window are no longer visible.\nFPS-independent speed # At the start of the project the speed of the balls were dependent on the FPS of the application. This is often not desirable in games or animations because that means that the higher FPS the faster the game will move and you cannot manually control the speed. FPS in games is often not stable. It doesn\u0026rsquo;t sit on just 60 FPS unless you lock it to max 60 and assuming your computer can handle it, but there\u0026rsquo;s still the possibility that it occasionally drops slightly. So even small fluctuations could change the game speed if you don\u0026rsquo;t lock it. The way I solved it, which probably isn\u0026rsquo;t a perfect solution, was to lock it to a set amount of moves per second. Depending on how much time had passed since the last move it multiplies the velocity vector by the time difference. A time difference of 1 would indicate that exactly the right amount of time had passed. Shorter time would make it move shorter distance and longer time makes it do longer jumps, which evens it out. Although one problem with this would be if you have a really slow computer the time difference will become really high and the blue balls will make large jumps, possibly going over the green balls.\nCircles and Arcs # The X11 library provides types for drawing rectangles and arcs (circles). One issue I had with the pre-existing XArc was that it uses integers for position. Which makes sense given that the screen is made up of pixels and that is how X11 interacts with the screen, it colors pixels on it. But I couldn\u0026rsquo;t use this XArc for my animation because of several reasons. One being that I simply needed more fields, like ones for velocity. But I also wanted float for the position. This was so the multiplication with the time difference previously explained would work correctly. Too low velocity and too fast computer could possibly result in the integers always being rounded down and therefore getting stuck in one place. I never experienced this issue myself, but I wanted to counteract this anyways.\nAnother annoying issue with the circles is that when you tell X11 to draw a circle (using XDrawArc) the coordinates you give are in the upper left corner, as if it was a rectangle. It is not at the center of the circle. At the start I made a function called get_center that returned the x and y of the center of the circle. When I later made my own Circle struct I decided to make the coordinates be the center of the circle because those coordinates are used much more when moving and calculating the physics and collisions. Then I simply provided a function for drawing the circles that subtracted the radius from the x and y positions, since this was the only place I would ever need those coordinates. Everywhere else I needed the center of the circle.\nRedrawing and double buffers # X11 doesn\u0026rsquo;t have any concept of objects in the window. All it does is draw the pixels you tell it to draw. To move a ball I had to paint over the previous position with white (the background color) and then redraw it in the new position. This meant that I had to erase and redraw everything that was somehow affected by the change in position. The blue balls would sometimes enter the green balls slightly, and since I wasn\u0026rsquo;t redrawing the green balls (as they didn\u0026rsquo;t move) it ended up making tunnels and craters in the green balls when the balls erased their previous position with white. Due to this issue I decided to always draw the green balls for every frame as well.\nThis was working alright for a while, but then I decided to increase the amount of blue balls. This resulted in a lot of flickering on the screen. To solve this I used the Xdbe functions for double buffers. This provides a drawable buffer that you can write to and when you are done writing you call the function XdbeSwapBuffers to place the buffer contents on screen. The buffer also always starts blank so everything has to be redrawn every frame, so I had no choice but to draw the green balls as well. Though the double buffers worked wonderfully. I was able to run it with 10 000 blue balls at once without any graphical glitches, although the window was so cluttered it was hard to see what was happening.\nMultithreading # The function XNextEvent locks the thread until it receives an event (an event specified by the previously mentioned XSelectInput). To be able to have continuous updating of the animation while also taking user input I needed to use a second thread. One thread to handle just the input, and another to handle all the animations. This also raises the major issue of multithreading, accessing the same data from different threads. I use the input to place down green balls, but the animation thread also needs the green balls to draw them. The usual solution to this is called mutex. A mutex is a variable that can be locked and unlocked. If it is locked then someone else (another thread) that tries to lock it will have to wait until the first thread unlocks it. Although mutex is no magical solution, you still need to be careful to make sure you lock it in all places where it accesses shared data. Semaphores also exist if you want to allow several, although limited, amount of threads to access something. But in this project I didn\u0026rsquo;t use the mutex library because X11 has its own functions for manipulating the window from different threads. To use these you must first initalize it with XInitThreads(), otherwise it won\u0026rsquo;t even let you access it from other threads. Then you use XLockDisplay(display), which is pretty much the pthread_mutex_lock(mutex) function. I don\u0026rsquo;t know what makes it special, but it was easy to use this to lock some shared variables as well since most of the time when I needed to lock something I was also gonna draw.\n","date":"2 August 2021","permalink":"/blog/bouncing-balls-simulation-using-x11/","section":"Blog","summary":"Recently I got the idea that I wanted to experiment with using X11 directly, instead of some higher-level library where buttons and fields already exist as objects. The goal was to get a better idea of how the graphics and window systems works in Linux (X11 specifically). This wasn\u0026rsquo;t a huge project and I only got to see parts of it before moving on, but it was a very interesting experience.","title":"Bouncing balls simulation using X11"},{"content":"","date":"25 July 2021","permalink":"/tags/computer_science/","section":"Tags","summary":"","title":"computer_science"},{"content":" In this post we will take a closer look at functions and some mathematical concepts relating to them. This post assumes you are familiar working with functions in some programming language and some mathematical knowledge of functions as well (like knowing what \\(y = f(x)\\) means and what a set is).\nTerminology and notation # Before getting into the main topic I want to cover some terminology and notation. Sets are denoted as an uppercase letter in math-style font like \\(A\\). When I say that an element maps to another it is simply a way of saying that some element \\(x\\), when given as argument to \\(f\\) will return an element \\(y\\), or as an equation \\(y = f(x)\\), \\(x\\) maps to \\(y\\). A transformation from \\(x\\) to \\(y\\). A function/mapping is simply a transformation from one thing to another. One goes in, another goes out.\nIt is also good to know the mathematical notation for the types of a function. \\(f : A \\rightarrow B\\) represents a function \\(f\\) that takes a single argument of type \\(A\\) and returns a value of type \\(B\\). To be more accurate, \\(A\\) and \\(B\\) aren\u0026rsquo;t types, but rather a set of possible values that can be input/output. But in the world of programming we often represent them as types like int, string, float, or similar. For example, the \\(log\\) function could be written as \\(log : \\mathbb{R}^+ \\rightarrow \\mathbb{R}\\), which means all positive real numbers as input and all real numbers as output. Although in the programming world it would instead be written as \\(log : \\text{float} \\rightarrow \\text{float}\\). \\(A\\) is called the domain. \\(B\\) is called the codomain. If we want to be more exact we use the term range to indicate all possible values that \\(f\\) can return. Which means that the range is a subset of the codomain. For example, for the function \\(f(x) = x^2\\) we can say it has the codomain \\(\\mathbb{R}\\), but if you inspect the function you will see that the range is only \\(\\mathbb{R}^+\\), only the positive real numbers since the function can never return any negative numbers.\nDeterminism and the definition of a function # Going strictly by the mathematical definition we don\u0026rsquo;t have any reference types (pointers) and no void functions. A function must always return a value for any element that is in its domain. Exceptions like values that will cause division by zero or other undefined computations will not be in that domain and are expected to not be put into the function. To be able to make any useful arguments regarding a function we must also require it to be pure.\nThe concept of pure functions only exist in the programming world, because in the world of math every function is pure. A pure function is one where the the return value only depends on the arguments. There cannot be any side effects. The function cannot print or write any values to external memory, and cannot read any values from the outside. These are what we call side-effects, inputs/outputs that are not the function arguments and return value. If we allow side-effects then the function becomes inherently non-deterministic, unpredictable. From here on when I say input I mean the arguments and output means return value. The simplest pure function we can have is the \u0026ldquo;constant function\u0026rdquo;. It takes 0 arguments and returns the same value every time it is called. Since we can\u0026rsquo;t have any side-effects that is all a function with no input can do. Below is an example of a constant function (written in Python). As you can see, if we don\u0026rsquo;t have any arguments there is no data to work with if we aren\u0026rsquo;t allowed side-effects.\ndef pi(): return 3.14159265359 This may seem restricting, but determinism in itself is a very useful property for a function. The same input will always give the same output. It\u0026rsquo;s very easy to test as it doesn\u0026rsquo;t depend on any state, which also makes it easier to debug. If you have some logical mistake in a deterministic function then all you need to do is find the mistake inside that function (assuming the input is correct, otherwise the issue is elsewhere). If it is non-deterministic function then you may need to look at all state that it is working with to find what goes wrong. You may need to debug much more outside of the function in question to find what leads to the invalid state.\nIf you don\u0026rsquo;t care about the formal definition then just skip to the next section. A formal definition is that a function \\(f : A \\rightarrow B\\) maps every element in a set \\(A\\) to some element in a set \\(B\\), and each element in \\(A\\) can only map to a single element in \\(B\\). This means that for any value \\(x \\in A\\), \\(f(x)\\) must always be the same value. Or expressed as a logical statement below: if \\(f(x)\\) returns two values \\(y_1\\) and \\(y_2\\) from the same \\(x\\) then \\(y_1 = y_2\\).\n\\( \\forall x. x \\in A. y_1 = f(x) \\wedge y_2 = f(x) \\implies y_1 = y_2 \\)\nIf the return values were different then that would contradict the definition of a function and it would also break the purity and determinism. If \\(y_1\\) and \\(y_2\\) are different for the same \\(x\\) then the function obviously has side-effects.\nInjective, surjective, and bijective # An injective function is a function \\(f : A \\rightarrow B\\) where no two elements in \\(A\\) returns the same element in \\(B\\). This is a function that is reversible because each value in the range has only one corresponding value in the domain. But that is only true for the range. Every value \\(y = f(x)\\) can be reversed to get back \\(x\\), but not every value in the codomain. The codomain may be a superset of the range, so there may be elements in the codomain that do not have any corresponding element in the domain. Some properties that derive from this is that the sets of the domain and range must be the same size, and the codomain must be equal or greater than the domain.\nA surjective function is the opposite of an injective. All elements in the codomain must be return values of some input to \\(f\\). Which means that the range = codomain. But the domain can be larger than the codomain since multiple elements of \\(A\\) can map to the same element of \\(B\\). There is no guarantee that the elements in \\(B\\) can be reversed since there may be several values of \\(A\\) that can give that output.\nBijective functions are functions that are both injective and surjective. When we put those two together we get a function that is a one-to-one mapping between the domain and codomain. It is always reversible in both directions and you can always create an inverse function that gives back the original (usually denoted \\(f^{-1}\\), where \\(f^{-1}(f(x)) = x\\)). Inverse operations can be useful when you want to undo something you have previously done or when you need to find out what the original was. For example, addition and subtraction are inverses. If we have \\(f(x) = x + 5\\) then the inverse of that is \\(f^{-1}(x) = x - 5\\).\nWhile bijective functions have a clear use-case of inverse operations, injective and surjective functions may be harder to find a good use for. Although it can be something to keep in mind when programming as they have some unique properties which you may be able to use for something.\nChaining functions # When we have functions that always return values and have well-defined domains and codomains then we can easily chain them. This is called function composition. In mathematical notation it looks like this \\( g \\circ f\\), which simply means \\(g(f(x))\\). But to do this the functions must have matching domains and codomains. If \\(f : A \\rightarrow B\\) then we must have \\(g : B \\rightarrow C\\) to be able to chain them. So if \\(h = g \\circ f\\) then \\(h : A \\rightarrow C\\) since it performs both \\(f\\) and \\(g\\). Composing functions like this is very good for creating a long pipeline of transformations. And if we stick to using deterministic functions then it becomes very clean looking code and the different components get separated into distinct parts where one returns what the next needs. When chaining functions it is important to keep track on the domain and range of your functions. If \\(g\\) can return a value that \\(f\\) cannot take as input then you have a problem.\nThe concept of chaining can be applied on reference types as well. It requires every method to return self or this or whatever your language calls the reference an object has to itself. So you could call methods like x.f().g().h() and so on, where each method modifies the internal structure as if those were the arguments. This is commonly seen in the builder pattern (C# example below). The non-object-oriented equivalent of that is h(g(f(x))), where x could just as well just be an object that holds some variables. The problem with determinism and purity in object oriented programming comes when a method both modifies the internal state and returns a separate value. Because at that point it has changed some state that is separate from the return value.\nHumanBuilder builder = new HumanBuilder(); Human human = builder.AddHead().AddBody().AddArms().AddLegs().Build(); There is nothing wrong with non-deterministic functions. Non-determinism is required to make any interesting program. And a lot of object oriented programming revolves around changing state. It just takes a different approach than the mathematical side. Although I do encourage you to write as much deterministic code as possible.\nOther types of mappings # Dictionaries, HashMaps, HashDictionaries, and the like are all mappings from one set to another. The key is the input and the value is the output. And as long as you don\u0026rsquo;t modify them they are deterministic. Although modifying them are often a key feature of using them. They may not be considered functions, but they are definitely relations, a superset of functions. A relation is just a mapping from one element to another, often denoted (1,2) when 1 maps to 2 (in function notation: \\(2 = f(1)\\)). Although relations are often represented as whole sets of mappings to indicate all possible relations like \\({(1,2), (2,3), (3,4), (4,5)}\\) to indicate a subset of the function \\(f(x) = x + 1\\) for integers.\nSwitch statements are also a type of mapping, and a function, from some variable value to a block of code. If that block of code is just a function that returns its value then you have a mapping from a value to a function (C# example below).\nswitch (x){ case 1 : return f(); case 2 : return g(); default: return h(); } Everything stated here extends easily to functions with multiple arguments or multiple return values, usually denoted as tuples. Although deciding if such functions are injective or surjective may become much harder. The notation for such a function is \\(f : A \\times B \\rightarrow C \\times D\\), where \\(A \\times B\\) means the Cartesian product of the sets \\(A\\) and \\(B\\). Meaning all possible combinations of the elements of the two sets. When you have multiple arguments the domain increases a whole lot in size, since now every element in \\(A\\) can be paired with every element in \\(B\\). The total domain size becomes \\(\\vert A \\vert \\times \\vert B \\vert\\) (size of \\(A\\) multiplied by size of \\(B\\)).\nFunctions and relations are everywhere in programming. In places you never considered before. Even your browser is a mapping that takes a URL and returns a webpage. Keep an eye out for them and see if you can use that knowledge to write cleaner and better code, and maybe catch some bugs.\n","date":"25 July 2021","permalink":"/blog/functions-a-deep-dive/","section":"Blog","summary":"In this post we will take a closer look at functions and some mathematical concepts relating to them. This post assumes you are familiar working with functions in some programming language and some mathematical knowledge of functions as well (like knowing what \\(y = f(x)\\) means and what a set is).","title":"Functions: a deep dive"},{"content":"","date":"25 July 2021","permalink":"/tags/math/","section":"Tags","summary":"","title":"math"},{"content":"Cellular automata is way to model biological systems through a set of cells that change their state based on their surroundings [ 1]. It requires some form of grid to operate on, where each location on the grid contains one cell. The cells are based on integer coordinates on the grid. The second requirement is a set of rules that determine when a cell should change state and to what state. The third and final requirement is an initial state, what it looks like at the start. Then the rules can be applied on all the cells to update their states. Applying the rules can be done as many times as you wish. Each application is called a step. Over time, when applying these rules certain behaviours may exhibit in the grid. This shows the interaction of the cells as a system.\nOne of the most famous cellular automata is Conway\u0026rsquo;s Game of Life and it models over- and underpopulation [ 1]. It takes place on a 2-dimensional plane of integers. Each cell can either be alive or dead. The rules are as follows:\nIf a cell has 0 or 1 living neighbour (out of its 8 neighbours) then it dies. If it is alive and has 2 or 3 living neighbours then it stays alive. If it is dead and has 3 living neighbours then it becomes alive. If it has 4 or more living neighbours then it dies. Too few neighbours and it dies of underpopulation, too many and it dies of overpopulation. Just the right amount and new cells are born. The image above shows a glider in Conway\u0026rsquo;s Game of Life. It is a set of cells that will continuously move diagonally (towards the bottom right in this image) until they collide with something else that disrupts the formation. Gliders are a stable formation because over a couple of steps it will return to its initial formation, thus making it go on forever in the same pattern.\nSome useful applications of cellular automata [ 2] include simulation of:\nGas spread Forest fire spread Bacterial growth Flow of electricity These are areas that can be hard and complex to model accurately using conventional computation methods, but by constructing simple rules a cellular automaton can represent them very well, and be computed in a very efficient manner.\nHeinonen and Pukkala [ 3] have applied cellular automata to forest planning using two-state cells on a hexagonal grid. With two states, one represented a stand (area of trees planted at the same time) that should be thinned out by cutting down some trees and the other represented a stand that should be kept as is. They later added a third state that indicated regeneration cutting, which means cutting down a lot or most of the trees to prepare for new trees. Using the cellular automata they have to compute way less than previous methods and also managed to get better results.\nCellular automata can also be self-organizing [ 4]. This means that over time they will tend towards a certain pattern, much like certain constructs that can be found in nature. Like cellular automata, biological systems also use small components to gradually build structures.\nReferences # [1] Eric W Weisstein. Cellular Automaton. URL: https://mathworld.wolfram.com/CellularAutomaton.html\n[2] Michael J Young. Typical Uses of Cellular Automata. Nov. 2006. URL: http://www.mjyonline.com/CellularAutomataUses.htm\n[3] Tero Heinonen and Timo Pukkala. \u0026ldquo;The use of cellular automaton approach in forest planning\u0026rdquo;. In: Canadian Journal of Forest Research 37 (Nov. 2007), pp. 2188-2200. DOI: 10.1139/X07-073\n[4] Stephen Wolfram. \u0026ldquo;Cellular Automata\u0026rdquo;. In: (1983)\n","date":"24 July 2021","permalink":"/blog/cellular-automata/","section":"Blog","summary":"Cellular automata is way to model biological systems through a set of cells that change their state based on their surroundings [ 1]. It requires some form of grid to operate on, where each location on the grid contains one cell. The cells are based on integer coordinates on the grid.","title":"Cellular automata"},{"content":"This article is intended to be read by someone who is looking to learn programming or is just starting out. This doesn\u0026rsquo;t tell you what programming language to choose or what tutorials to follow. Only some general tips to keep in mind when learning.\nWhat is programming? # Many people think that programming is all about writing code. But the main job a programmer does is solve problems. Writing code is just the actual solution to the problem. You still need to figure out how to solve it first. Just like an engineer must plan and measure everything before building a bridge, the bridge itself is the final product but many hours go into just figuring out how it should be done. Or if we compare it to math. Solving a math problem requires you to first figure out what kind of problem it is. What formulas will you need? Then once you know that you can start doing the calculations, the equivalent of writing code.\nProgramming problems are often generalized problems. The code should work for any values of x and y. A basic math question could be “If Bob has $5 and John has $3. Who has more money?”. This question can easily be answered by looking at the values. The bigger number is the answer. But if we generalize this to “If Bob has $x and John has $y. Who has more money?”. Now we only have x and y to work with, we can’t simply look at the number. We need to formalize a way to decide who has more money in terms of the variables x and y. Given that the answer depends on the values of x and y we need to ask the computer a question. The simplest question we can ask is “Is x bigger than y?”. If the answer is yes, then Bob has more. Else, John has more (or equal).\nHow to learn programming # The best way, and often the only way, to learn something properly is learning by doing. You don’t get good at math by reading problems, you get good at it by doing exercises, by using math. Same is true for programming. It is very important that you write a lot of code by yourself. Following along with a tutorial is a good way to learn, but don’t just write the same code they do. Play around with their code. Try your own variations. Think for yourself!\nI don’t know any French, but I can still write down what someone else is writing without ever learning what it means or how to use the words I’ve written. That’s why it’s important to experiment by yourself. And unlike learning a spoken language, programming languages will tell you if you are doing right or wrong. If it’s a syntax error, which means invalid grammar in the programming world, then the program will tell you so and approximately where the problem is (it\u0026rsquo;s not always exact, if you can\u0026rsquo;t find it then try looking at the lines before the error. Sometimes mistakes on previous lines aren\u0026rsquo;t considered errors until something else comes later). If it’s a logical error, you will find that out when you run the code and it doesn’t work as expected.\nWhich brings me to another point. Don’t be afraid of running your code. I often see beginners asking “is this correct?” and sending a code snippet. I always respond with “does it give the expected result?”, which more often than not gives back the response “I don’t know, I haven’t tried it”. Well, why haven’t you tried it? Don’t waste my time asking if it is correct when you can get the right answer in a few seconds yourself. A much better question to ask is “How can I improve this code?” or “Can I have some feedback on my code?” after you have solved a problem.\nHow to watch/read tutorials # When watching tutorials, or reading a book, or whatever way you choose to learn, don’t rush through the topics. Going through 20 topics in one day is going to leave you more confused than when you started. You are overloading your brain with new information. Take one or two topics/videos at a time and spend some time digesting that content until you have a decent understanding of it. I sometimes see these several hours long tutorials show up on YouTube. Just because it\u0026rsquo;s one video doesn\u0026rsquo;t mean you should binge watch it and then expect to have learnt it all. Most of them are divided into clear sections. Split up those 4-8 hours of video over the course of 2 weeks. Watch 30 minutes daily and focus on those parts. As I mentioned earlier, play around with the concepts covered in the tutorial. If you don’t understand it, rewatch it and try again, or ask someone else for an explanation. Sometimes it helps to hear it explained in a different way.\nIf you are struggling to understand or to solve a problem:\nGo back and read again to make sure you understand the concepts needed. Google for how to solve the problem (see section below on How to Google). Ask for help (see section below on How to ask for help) How to Google # When Googling for help you should be as specific as possible with your search query. If you are making a snake game, don’t google “How to make a Snake game?”. Instead search about exactly the part you are stuck on. Maybe the question should be “How do I make a program with graphics/colors?” or “How do I make my Snake longer?”, or even better if you can explain it in programming terms. The more general you can make your question the more likely you are to find an answer. This does not mean to ask vague questions. It should still be specific about the problem. It is also a good idea to start your query with the name of the programming language, for example, \u0026ldquo;python snake game how to make snake longer\u0026rdquo;. It can also be a good idea to leave out irrelevant words such as \u0026ldquo;the\u0026rdquo;, \u0026ldquo;i\u0026rdquo;, \u0026ldquo;a\u0026rdquo;. Shorter search queries are often better, as long as you don\u0026rsquo;t leave out any important details.\nHow to ask for help # Don’t ask for help immediately. Always try to find an answer online first by Googling. Spend maybe 30 minutes on Google, reading relevant articles or watching videos. Maybe even sleep on it and try again tomorrow. After that you can ask for help online. As an active helper online it is not fun to help someone who has put in zero effort to understand their problem. Sometimes I see people just posting the code and saying \u0026ldquo;it doesn\u0026rsquo;t work\u0026rdquo;. Sometimes they can\u0026rsquo;t explain in what way their code doesn\u0026rsquo;t work, that shows that you haven\u0026rsquo;t even understood what you are trying to do. It should be easy to say \u0026ldquo;X should happen but Y happens instead\u0026rdquo;. Why should we put in the effort to help you if you aren\u0026rsquo;t willing to put in the effort yourself? By searching online first you may also get some understanding, which might get clarified by someone explaining directly. Even if you don\u0026rsquo;t find your answer online you will still have had some ideas put in the back of your mind.\nDiscord communities are a great place for beginners. When you finally ask for help, be as specific as possible. Explain the issue in detail and provide all information about the problem (if it’s an exercise you have found somewhere then please send the whole exercise description or a link to it). Sending parts of the relevant code is also very helpful. Going back to the previous example of “How do I make my snake longer?” you will probably need to explain how you have coded your snake so far and show the code for it. That way you can get help with how you should proceed. Without knowing what your code looks like you often can’t get an exact answer to such a question. Depending on what your code looks like one solution may be much more difficult than another.\nI also recommend reading this: dont\u0026rsquo; ask to ask, just ask. In short, don\u0026rsquo;t ask \u0026ldquo;can anyone help me with X?\u0026rdquo;. Instead explain your problem directly.\n","date":"23 July 2021","permalink":"/blog/programming-how-to-learn-it-and-how-to-get-help./","section":"Blog","summary":"This article is intended to be read by someone who is looking to learn programming or is just starting out. This doesn\u0026rsquo;t tell you what programming language to choose or what tutorials to follow. Only some general tips to keep in mind when learning.\nWhat is programming? # Many people think that programming is all about writing code.","title":"Programming: how to learn it and how to get help."},{"content":" Introduction # The W algorithm developed by J. Hindley and R. Milner is used to infer the types of a programming language where no types have been explicitly written. Several functional languages today use this kind of inference, for exampel F# and Haskell (although Haskellers still like to write out the types). The method works by assuming everything is a different generic type. The types of any pre-existing functions and any constants will be known before starting. So if there is a 0 in the code then that is an integer, 0.0 is a float, [] is a generic list.\nFinding the types # Types with an apostrophe before them means they are generic. A type is written with the syntax variable_name : variable_type.\nWe begin with a simple example. Below we have the identity function written in F#. It takes in an element and returns back the same element.\nlet id x = x To calculate the types of this function we start by setting all unknown values to a generic type.\nx : \u0026#39;a id : \u0026#39;b -\u0026gt; \u0026#39;c The variable x has the generic type 'a and the function id has the generic type of 'b -\u0026gt; 'c. Because the input of the function is x and x has the generic type 'a then the function input must also have the same type.\nx : \u0026#39;a id : \u0026#39;a -\u0026gt; \u0026#39;c The only possible output of this function is also the value of x. Thus the return value of the function must also be 'a.\nx : \u0026#39;a id : \u0026#39;a -\u0026gt; \u0026#39;a And now we\u0026rsquo;re done with that function. All values have been reduced to the same type. There are no further reductions to be done. The identity function has the type 'a -\u0026gt; 'a because it will always return the same value it is given.\nA more complicated example # Below we have a function of which we do not know any of the types for.\nlet rec myfunc f xs = match xs with | [] -\u0026gt; [] | x::xs -\u0026gt; f x :: myfunc f xs We start by finding the types of all our constants and pre-existing functions and then giving a generic type to all our unknowns.\n[] : \u0026#39;a list (::) : \u0026#39;b -\u0026gt; \u0026#39;b list -\u0026gt; \u0026#39;b list f : \u0026#39;c x : \u0026#39;d xs : \u0026#39;e myfunc : \u0026#39;f We can see that the parameters for myfunc are f and xs. Therefore 'f = 'c -\u0026gt; 'e -\u0026gt; 'g\nf : \u0026#39;c x : \u0026#39;d xs : \u0026#39;e myfunc : \u0026#39;c -\u0026gt; \u0026#39;e -\u0026gt; \u0026#39;g To start figuring out what the types are we can start by looking at the match statement. It matches on xs and the first pattern it suggests that it is of type 'a list. The second pattern is a deconstructing pattern with the cons operator. Because of the :: operator that means x : 'b and xs : 'b list, and the return value of the :: operation and the second pattern match is therefore 'b list. We can therefore say that 'e = 'a list = 'b list, which in turn implies that 'd = 'a = 'b.\nf : \u0026#39;c x : \u0026#39;a xs : \u0026#39;a list myfunc : \u0026#39;c -\u0026gt; \u0026#39;a list -\u0026gt; \u0026#39;g Now there\u0026rsquo;s only 'c and 'g left to figure out. We\u0026rsquo;ll start with 'g'. The return value of the first pattern match is an empty list 'h list. Note that this is the second empty list we use and it is not guaranteed to be the same type as the first. Same goes for the :: operator. The second pattern match returns the result of the :: operation, which we\u0026rsquo;ll call 'i list. If the cons operator is to work on its arguments the left side must be 'i and the right side must be 'i list. Therefore myfunc must return an 'i list. And since the only other return value of myfunc is 'h list we can draw the conclusion that 'g = 'h list = 'i list, which implies 'h = 'i. Since we said earlier that x : 'a and the left input to :: is 'h we know that f : 'a -\u0026gt; 'h.\nf : \u0026#39;a -\u0026gt; \u0026#39;h x : \u0026#39;a xs : \u0026#39;a list myfunc : (\u0026#39;a -\u0026gt; \u0026#39;h) -\u0026gt; \u0026#39;a list -\u0026gt; \u0026#39;h list And then we fix it up a little by using only the first letters of the alphabet.\nf : \u0026#39;a -\u0026gt; \u0026#39;b x : \u0026#39;a xs : \u0026#39;a list myfunc : (\u0026#39;a -\u0026gt; \u0026#39;b) -\u0026gt; \u0026#39;a list -\u0026gt; \u0026#39;b list The final type of myfunc is ('a -\u0026gt; 'b) -\u0026gt; 'a list -\u0026gt; 'b list. Any experienced functional programmer should now see what function it is, if they didn\u0026rsquo;t already see it the second they saw the function definition. It is of course the famous map function, or more specifically the map function for lists.\nIntroducing a type error # Now lets say we instead have the same function but a :: switched out for a +.\nlet rec myfunc f xs = match xs with | [] -\u0026gt; [] | x::xs -\u0026gt; f x + myfunc f xs The plus operator has the type (+) : 'num -\u0026gt; 'num -\u0026gt; 'num where 'num symbolizes a generic number type (eg. int, float, double). This would mean that f : 'a -\u0026gt; 'num. But the returning value of myfunc can\u0026rsquo;t be a 'num because the first case of the pattern match says it\u0026rsquo;s an 'h list. Now we have reached a type error and compilation can stop here. This code will not compile because the types for + doesn\u0026rsquo;t match.\nExercise for the reader # let exercise l = match l with | [] -\u0026gt; 0 | x::xs -\u0026gt; if x \u0026gt; 0 then x + exercise xs else exercise xs ","date":"26 February 2020","permalink":"/blog/type-inference-with-hindley-milner-w-algorithm/","section":"Blog","summary":"Introduction # The W algorithm developed by J. Hindley and R. Milner is used to infer the types of a programming language where no types have been explicitly written. Several functional languages today use this kind of inference, for exampel F# and Haskell (although Haskellers still like to write out the types).","title":"Type inference with Hindley-Milner W algorithm"},{"content":" Introduction # Most programming languages today have a bunch of operators for different purposes. Usually for mathematical, logical, comparison, and bitwise operations. +, -, *, /, \u0026amp;\u0026amp;, ||, exists in probably every modern language. Developers expect them to exist; no one would want to program without them.\nMany languages like to extend their operators, usually +, to work on several types. Python allows using the plus operator on both strings and numbers. The interpreter accepts both \u0026quot;AB\u0026quot; + \u0026quot;CD\u0026quot; and 3 + 5; but these are not the same operation, just the same operator. Addition on numbers is commutative, 3 + 5 == 5 + 3; addition on strings is not, \u0026quot;A\u0026quot; + \u0026quot;B\u0026quot; != \u0026quot;B\u0026quot; + \u0026quot;A\u0026quot;.\nOperator:\na symbol or function denoting an operation (e.g. ×, +).\nOperation:\nan action to be performed on some data.\nLanguages do this through operator overloading, either built in to the compiler/interpreter, or as a part of the actual language. You specify what operation an operator should do for a specific class/type. While integer addition adds up the numbers, string addition (also known as concatenation) appends the second string to the end of the first to create a new string. If you do add any yourself, you shouldn\u0026rsquo;t give them completely different behavior than what the symbol usually means. Using the + operator on Vectors shouldn\u0026rsquo;t perform a cross product just because you thought it seemed convenient.\nOperators as functions # You may think of operators as these magical symbols that the developers programmed into the language. While partially true, you can also see an operator as a infix function (excluding Lisp, where everything is prefix). Think of \u0026gt; as a function. What parameters does it have and what does it return?\nClick to expand: greater-than type signature {% highlight fsharp %} (int -\u003e int -\u003e bool) {% endhighlight %} In a more familiar style: {% highlight csharp %} bool greaterThan(int a, int b); {% endhighlight %} This is not accounting for any other possible operator overloading, such as strings or other number types (eg. float/double). Some programming languages lets you treat operators like a function. In the code snippet below, we assign the plus operation to the function addition\naddition = (+) -- (int -\u0026gt; int -\u0026gt; int) addition 3 5 -- returns 8 Haskell also lets you treat regular functions as infix function.\n3 `addition` 5 -- returns 8 You can usually express operators in terms of other operators. In C you can define + and - using bitwise operators; and in turn you can define * and / with those. Assuming you have other language constructs such as loops and if-statements available. Integer equality and comparison can be expressed with the help of subtraction. Logical operators can be expressed with equality.\nAt the time of writing this I am currently working on making an interpreter for my own Lisp-like language. I was having some trouble figuring out how to handle the operators. Do I treat them as functions? Or is it better to see them as operators and parse them as such? To minimize the amount of operators I realized I could define the logical operators with the help of only the equality operator; and could thus put them in the standard library for the language. A few less operators to worry about. Unfortunately I couldn\u0026rsquo;t take it any further than that; as the language I\u0026rsquo;m making is rather high-level. The rest of the standard operators are hardcoded in the parser, but are parsed as function calls to allow for easier partial application and less types to worry about.\nbool and(bool a, bool b){ if(a == true){ if(b == true){ return true; } } return false; } Defining your own operators # Once again, only some languages allow defining custom operators. When talking about operators I am speficially talking about binary operators in this context. An example of a unary operator (one argument) is - when placed right in front of a numerical to create a negative number a = -2. A ternary operator (three arugments) commonly exists in the form of a one line if-else statement condition ? when true : when false. Less common operators like unary and ternary have their uses, but not in this post.\nDefining your own operators has no logical benefit in the sense that it changes the way your program works. You could consider it syntactic sugar, but it can improve readability a lot. If you find yourself in a project where you are using a certain functionality a lot, you can consider if you want to make a custom operator. The symbols I chose for the example below has no meaning in any context that I am aware of, other than that they are legal symbols for custom operators in Haskell.\nadd5div a b = (a + 5) / (b + 5) ( \u0026lt;@\u0026gt; ) a b = add5div a b 10 \u0026lt;@\u0026gt; 5 -- returns 1.5 Haskell has a bunch of code-defined operators in the standard libary to help with certain actions in its very intricate type system. For example: $, \u0026lt;$\u0026gt;, \u0026lt;*\u0026gt;, and \u0026gt;\u0026gt;=.\nDefining custom operators is more common in functional programming languages than imperative ones. Imperative has all these state-manipulating statements and function calls, while in functional languages everything is done by composing functions, which makes operators very useful. Instead of passing two different data into a function as arguments, you use that function as an operator to make it look more elegant. Function calls become less cluttered and, if you are familiar with the operator, easier to read.\n","date":"9 December 2019","permalink":"/blog/operators-are-functions-too/","section":"Blog","summary":"Introduction # Most programming languages today have a bunch of operators for different purposes. Usually for mathematical, logical, comparison, and bitwise operations. +, -, *, /, \u0026amp;\u0026amp;, ||, exists in probably every modern language. Developers expect them to exist; no one would want to program without them.\nMany languages like to extend their operators, usually +, to work on several types.","title":"Operators are functions too"},{"content":" Static and dynamic typing explained # Static typing can find type errors reliably at compile time, which should increase the reliability of the delivered program -- Wikipedia\nA statically typed programming language checks that the types of everything matches. If something doesn\u0026rsquo;t match, the compiler stops and displays an error. This guarantees type safety to a certain degree, without even running the program. A variable has one type and one type only. It can never change its type. This eliminates a lot of errors, and you can spend less time testing it.\nA language with dynamic type checking has its types checked during runtime. These languages often leave out type declarations in the code, leading to less code to read and write. Checking during runtime adds extra overhead when running, and increases the likelihood of runtime type error. Since it only checks the types it encounters, it won\u0026rsquo;t validate the types in any execution paths you don\u0026rsquo;t test.\nThe code snippet below contains two separate execution paths, and depending on what value some_condition holds, the else condition may or may not run.\nif some_condition: print(1 + 1) else: print(1 + \u0026#34;1\u0026#34;) Someone who has used Python may see that the addition in the else path will throw a type error. A statically typed language would catch the error compile-time. Python, however, has a dynamic type system and will not notice the type error if execution doesn\u0026rsquo;t go down that path. Imagine the condition being something that evaluates to True 99% of the time. You could continue coding for a good while before noticing your mistake.\nStatically typed languages, while type safe to a certain degree, can still contain dynamically typed parts. Languages that make use of inheritance (eg. C#, Java, C++) tend to mix static and dynamic typing. A variable of type A can also hold an instance of any subclass to A. This works because any subclass of A can do everything that A can do. Although it can\u0026rsquo;t use the subclass\u0026rsquo; additional functionalities while assigned to a variable of the supertype, you can downcast the object to its actual type.\nWhen a variable contains an object of a different type than declared, we speak of actual type (the type of the object, possibly a subclass) vs. apparent type (the type of the variable). Here the dynamic part comes in. Because the actual type of the object may differ from the apparent type, we can\u0026rsquo;t know at compile-time if we can downcast. Different execution paths may lead to the variable containing a different subclass.\nOnly when we know the actual type of the variable can we tell if the code allows the downcasting or not. If not it usually results in a runtime error.\nStatic typing # Statically typed languages tend to have better code completion. With your text editor correctly set up you can get red squiggly lines under a lot of what would result in a compiler error, saving you some time. You can also see the type signatures of variables and functions, reducing the chances of making incorrect assumptions.\nmap(function, iterables) The snippet above shows the type signature for the function map in Python. We can see that it wants a function and an iterable for input, according to the hopefully well-named parameters. Without knowing the meaning of map you can\u0026rsquo;t tell what arguments you should pass to it. You could somewhat assume what counts as iterable, but it doesn\u0026rsquo;t classify exactly what defines an iterable. Looking at the function parameter we can\u0026rsquo;t tell anything about what type the argument should have.\nIEnumerable\u0026lt;R\u0026gt; Select\u0026lt;T,R\u0026gt;(IEnumerable\u0026lt;T\u0026gt;, Func\u0026lt;T,R\u0026gt;) Here we have the type signature for the same function in C#. T and R represents two generic types. We do not care about the actual types of the arguments, as long as all T\u0026rsquo;s have the same type; and same goes for the R\u0026rsquo;s.\nFor the first argument you can pass it any C# class that implements the interface IEnumerable\u0026lt;T\u0026gt; of any type T. As opposed to Python, it clearly states what defines an iterable.\nFunc\u0026lt;T,R\u0026gt; represents a function that takes a value of type T and returns a value of type R. This means that if we pass in a list of integers, we must also pass in a function that takes an integer as input, and we will receive an IEnumerable of type R as output. The compiler will complain if we pass it anything that doesn\u0026rsquo;t match.\nStatic typing tends to make languages more verbose when explicitly stating the types, but not necessarily. Some languages have a strong type inference.\nmap f [] = [] map f (x:xs) = (f x) : map f xs The snippet above shows a simple implementation of map in Haskell. By analyzing how I\u0026rsquo;ve used lists, list operators, and functions, it can infer the type signature (a -\u0026gt; b) -\u0026gt; [a] -\u0026gt; [b]. This matches the type signature of C#\u0026rsquo;s Select, a is the T and b is the R, although the parameters have swapped places. C# has it the other way because there you typically use it by doing someObject.Select(function) on an object, instead of passing in the object as a parameter. Haskell on the other hand, makes use of partial application where it makes more sense to apply the function first.\nDynamic typing # Dynamically typed languages, while more overhead, usually have no compilation stage, and can thus run immediately. Compiling a large project can take several seconds, if not minutes. When you first learn a compiled language, the compilation step may not feel like any hindrance; as a small program can take less than a second to compile.\nNo compilation opens up for a new cool possibility for testing your code. A compiled language can only run your test cases as often as you compile; but in a dynamically typed language you can set up your tests to run whenever you save a file. This way you can constantly keep track of if you break something. If, however, you are a save-maniac like me, who hits Ctrl+S every few seconds, you may want to learn to control yourself.\nDynamic typing tends to lead to less verbose languages. Without static type checking, the need to write out types disappears. This lowers the bar for newcomers. A less verbose language with no strict compiler yelling at them usually appears more welcoming. If you compare the previously mentioned code snippets of map in Python to the Select in C#, you can easily guess which one a new programmer would go for.\nMy experiences and opinions # I was first introduced to programming through my university when I began studying computer science. The first course taught the statically typed language C, and later on C#. The whole first year consisted of only statically typed languages before finally reaching the dynamically typed JavaScript in a course in web development. Using JavaScript felt odd, there were a lot of features I missed. Mainly the code completion and variable/function suggestions. I ran into a great deal of bugs and unexpected behavior; I guess some of these can be attributed to JavaScript specifically.\nI have tried Python as well, and I had similar experiences to JavaScript with it. So as of now I am on the static side. I am, however, in no way saying that either is better or worse than the other. This just happens to be my opinion on it. Someone who was taught Python as their first language may be more inclined to prefer dynamic type systems.\n","date":"21 November 2019","permalink":"/blog/static-vs-dynamic-typing/","section":"Blog","summary":"Static and dynamic typing explained # Static typing can find type errors reliably at compile time, which should increase the reliability of the delivered program -- Wikipedia\nA statically typed programming language checks that the types of everything matches. If something doesn\u0026rsquo;t match, the compiler stops and displays an error.","title":"Static vs dynamic typing"},{"content":"My name is Casper Andersson and I currently work as a software developer. I enjoy most types of non-UI programming. I am absolutely trash at doing pretty user interfaces and prefer my programs to stay within the terminal. Due to my job my interests currently lie in C programming and computer networks. On top of programming I also really like to write technical blogposts and documentation.\nExperience # Westermo Network Technologies 2021 – present Software Developer Working with embedded Linux systems on network switches. Driver development in the Linux kernel, including some upstreaming. Focusing on time synchronization and time-sensitive networking. Mälardalen University 2018 – 2021 Bachelors Degree in Computer Science Thesis: Reservoir Computing Approach For Network Intrusion Detection On top of my studies I also worked as an assistant in a course on Introduction to Programming in C a couple times. The tasks included helping students with their assignments and answer any questions they had regarding programming and the course. Notable courses: DVA234 - Databases DVA218 - Data Communication DVA229 - Functional Programming with F# DVA315 - Operating Systems DVA339 - Compiler Theory DVA340 - Artificial Intelligence MAA507 - Mathematics of Internet MMA500 - Discrete Mathematics, a Second Course ","date":"1 January 0001","permalink":"/about/","section":"Casper Andersson","summary":"My name is Casper Andersson and I currently work as a software developer. I enjoy most types of non-UI programming. I am absolutely trash at doing pretty user interfaces and prefer my programs to stay within the terminal. Due to my job my interests currently lie in C programming and computer networks.","title":"About Me"},{"content":"Here is documentation for some of my projects\n","date":"1 January 0001","permalink":"/docs/","section":"Documentation","summary":"Here is documentation for some of my projects","title":"Documentation"}]